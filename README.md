# -GENERATIVE-TEXT-MODEL

COMPANY: CODTECH IT SOLUTIONS

NAME: Mohith B

INTERN ID: CT06WRL

DOMAIN: Artificial intelligence

DURATION: 6 WEEKS

MENTOR: NEELA SANTOSH

TASK 4

#Objective

The goal of Task 4 was to create a Generative Text Model that can produce coherent paragraphs based on user-defined prompts or topics. This task showcases the power of Natural Language Generation (NLG), a key area of Artificial Intelligence (AI) that enables machines to generate human-like language.

#What Is the Tool We Created?

We developed a text generation tool using the GPT-2 model from Hugging Face's Transformers library. GPT-2 (Generative Pre-trained Transformer 2) is a deep learning-based language model capable of generating fluent and contextually relevant text given a small prompt.

ðŸ”¹ Functionality:
Accepts a user-defined prompt (e.g., a sentence or topic).

Uses GPT-2 to generate a paragraph or continuation of the input.

Prints the result to the screen (or optionally saves it).

ðŸ”¹ Model Used:
GPT-2 (gpt2) â€” a 124M parameter transformer-based model.

Fine-tuned for open-ended text generation.

ðŸ”¹ Key Features:
Human-like text output.

Supports creative writing, topic expansion, storytelling, etc.

Fully customizable (max length, randomness/temperature, etc.).

#Platform & Technology Stack

Component	Details

Language:	Python

Libraries:	transformers (by Hugging Face)

Model:	gpt2 (Generative Pre-trained Transformer 2)

Execution:	Python script (text_generator.py)

Runtime:	CPU (or GPU for faster inference)

Development:	Any Python IDE / Terminal 

#How the Tool Works (Behind the Scenes)

User Input:

The user enters a prompt or topic via the command line (e.g., "The future of AI").

Model Inference:

The prompt is tokenized and passed to the GPT-2 model.

The model generates the next tokens in the sequence until a stopping condition is met (e.g., max_length).

Text Output:

The generated text is decoded into human-readable format and printed to the terminal.

#Why This Is Valuable

Text generation is one of the most impressive applications of large language models (LLMs). It demonstrates the machine's ability to understand context, predict language structure, and create grammatically coherent content â€” making it useful across journalism, marketing, education, and entertainment.

This task equips you with practical experience in deploying pretrained transformer models and using language AI responsibly and creatively.

OUTPUT:

![Image](https://github.com/user-attachments/assets/5aaf736c-f9de-47d9-8efa-bd0b90a1ef99)
